## Chapter 2 - Telemetry Application Stack 2/3: KOLEKTOR

> :white_check_mark: Wiemy już jak skonfigurować telemetrię na urządzeniach IOS-XR, a także Bazę Danych w celu przechowywania pobranych danych.
> :arrow_down: Teraz czas na konfigurację kolektora! :clap: <br>

Skonfiguruj kolektor danych **Pipeline** w celu zbierania strumieni z danymi, z urządzeń IOS-XR i umieść je w bazie danych InfluxDB.

**Pipeline** jest już pobrany dla Ciebie.
Do własnego użytku - możesz pobrać go stąd - https://github.com/cisco/bigmuddy-network-telemetry-pipeline 

Kontynuuj w uprzednio otwartym **Terminalu**.

### 1. krok - Pipeline.conf: INPUT
W celu odbioru strumieni danych wysłanych przez ruter do kolektora - odpowiednia konfiguracja musi zostać wdrożona w pliku *pipeline.conf*.
Ta konfiguracja jest zawsze **domyślnie** umieszczona w tym pliku, więc jeśli nie potrzebujesz tego skonfigurować w inny sposób - zostaw to domyślne ustawienie. **W tym przypadku - nie dokonuj żadnych zmian.**
<img align="center" width=60% src="/readme/2B_1.png"></img>

### 2. krok - Pipeline.conf: OUTPUT
W celu wysłania dalej zebranych danych do bazy danych - **dodaj** konfigurację opisującą InfluxDB do pliku *pipeline.conf*.  
```console
root@ubuntu:~/# cd /root/bigmuddy-network-telemetry-pipeline/bin
```
Dołącz na końcu pliku *pipeline.conf* konfigurację miejsca, gdzie chcesz aby wysłać zebrane dane. Edytuj plik przy pomocy **vim** lub **nano** zgodnie z Twoją preferencją. Konfiguracja jest zaprezentowana poniżej:
```
[mymetrics]
stage = xport_output
type = metrics
file = /root/bigmuddy-network-telemetry-pipeline/metrics.json
output = influx
influx = http://198.18.134.28:8086
database = TELEMETRY_DATA
```

### 3. krok - Metrics.json
Wyjdź z folderu bin i edytuj tym razem plik *metrics.json* w celu określenia dokładnych metryk, które mają zostać umieszczone w bazie danych (z modelu danych YANG):
```console
root@ubuntu:~/# cd /root/bigmuddy-network-telemetry-pipeline
```
Edytuj plik *metrics.json* tak jak przedstawiono poniżej, przy pomocy **vim** lub **nano** (zgodnie z Twoją preferencją):
```json
[
  {
    "basepath" : "Cisco-IOS-XR-ipv4-bgp-oper:bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor",
    "spec" : {
      "fields" : [
         {"name" : "neighbor-address", "tag" : true},
         {"name" : "connection-state"}
      ]
    }
  }								
]
```  
Przykładowe wpisy w bazie danych będą wyglądały następująco: 
<img align="center" width=60% src="/readme/2B_2.png"></img>

### 4. krok - Synchronizacja
Uruchom skrypt w celu zapewnienia synchronizacji pomiędzy maszyną wirtualną z bazą danych i urządzeniami XR:
```console
root@ubuntu:~/# python /root/synchronize.py
```

### 5. krok - Uruchom Pipeline
Otwórz Terminal i przejdź do folderu bin pobranego kolektora Pipeline:
```console
root@ubuntu:~/# cd /root/bigmuddy-network-telemetry-pipeline/bin
```
Uruchom Pipeline:
```console
root@ubuntu:~/bigmuddy-network-telemetry-pipeline/bin# ./pipeline
```
Wprowadź dane do logowania dla InfluxDB, 
**Username:** admin  
**Password:** admin  

Nie zamykaj okna z uruchomionym kolektorem Pipeline.

---
<h4 align="center">[4/6]</h4>
<h4 align="center"> <a href="/readme/2.md"> :arrow_left: Telemetry Application Stack 1/3 </a> || <a href="/readme/4.md"> Telemetry Application Stack 3/3 :arrow_right: </a> </h4>
